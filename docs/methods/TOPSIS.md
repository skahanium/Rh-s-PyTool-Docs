# TOPSIS——优劣解距离法

## 概念

**TOPSIS （Technique for Order Preference by Similarity to an Ideal Solution ）法**由C.L.Hwang和K.Yoon于1981年首次提出，TOPSIS法是根据有限个评价对象与理想化目标的接近程度进行排序的方法，是在现有的对象中进行相对优劣的评价。[^1]

[^1]: [TOPSIS法_百度百科](https://baike.baidu.com/item/TOPSIS%E6%B3%95)

## 基本原理

由中文名望名知意，TOPSIS表明一个指标距离其最优值的距离越近越好，距离其最劣值的距离越远越好。基本过程为基于归一化后的原始数据矩阵，采用余弦法找出有限方案中的最优方案和最劣方案，然后分别计算各评价对象与最优方案和最劣方案间的距离，获得各评价对象与最优方案的相对接近程度，以此作为评价优劣的依据。该方法对数据分布及样本含量没有严格限制，数据计算简单易行。[^2]

[^2]: [TOPSIS法介绍及python3实现](https://zhuanlan.zhihu.com/p/37738503)

通俗的例子：小明数学考试 134 分，要怎么知道他的成绩是好还是不好呢？

- 基于分布的评价方法会观察小明的分数位于班级分数的哪个水平（如前 5%、前 10%），但这种评价方法只能给出一个方向的情况。如班上成绩除了最高分外，其余都是 134 分，那么小明的成绩就是并列的倒数第一，但是正向评价给出的结果是前 5%。
- 而 TOPSIS 就是找出班上最高分（假设是 147 分）、最低分（假设是 69 分），然后计算小明的分数和这两个分数之间的差距，从而得到自己分数好坏的一个客观评价。距离最高分越近，那么评价情况越好，距离最低分越近，那么评价情况越糟。



## TOPSIS计算过程

（1）输入观测值数量为$m$的原始数据集$X=\{x_1, x_2, ..., x_n\}$，指标权重$\omega = \{\omega_1,\omega_2,...\omega_n\}$。

（2）将指标中的非正向指标转变为正向指标。

（3）将转变后的数据集进行向量归一化，得到标准化矩阵$Z=\{z_1,z_2,...z_n\}$。

（4）创建$m \times n$的矩阵$D_1$、$D_2$，其中$D_1$的每一列都由该列对应指标的最大值填充，$D_2$的每一列都由该列对应指标的最小值填充。

（5）利用$Z-D_1$、$Z-D_2$得到与最优、最劣矩阵的距离矩阵$C_1$、$C_2$。

（6）假设$c^1_{i,j}$为矩阵$C_1$第$i$行第$j$列的元素，$c^2_{i,j}$为矩阵$C_2$第$i$行第$j$列的元素，利用指标权重$\omega = \{\omega_1,\omega_2,...\omega_n\}$，计算各评价对象与最优方案、最劣方案的接近程度：

$$
R_i^+ = \sqrt{\sum_{j=1}^n \omega_j*(c^1_{i,j})^2}
$$

$$
R_i^- = \sqrt{\sum_{j=1}^n \omega_j*(c^2_{i,j})^2}
$$

（7）结合最优、最劣方案得出TOPSIS值：

$$
TOPSIS_i = \frac{R_i^-}{(R_i^- + R_i^+)}
$$



 由上式可知 $0 \leq TOPSIS_i \leq 1$，且$TOPSIS_i$越大表明评价对象越优。

（8）如有必要，可根据$TOPSIS_i$大小进行排序分档。



## 可用函数

TOPSIS方法的python函数`topsis`被包含在index_calmeth模块的evaluation之中，用法参照[此处](../api/index_calmeth.md#topsis)，实例参照[此处](../examples/index_calmeth.md#topsis)。


